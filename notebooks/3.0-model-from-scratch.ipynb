{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Hypothesis 1 test\n",
    "Create my own model and train it on given dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import torch\n",
    "\n",
    "torch.manual_seed(420)\n",
    "np.random.seed(420)\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('../data/internal/train.csv')\n",
    "test_df = pd.read_csv('../data/internal/test.csv')\n",
    "val_df = pd.read_csv('../data/internal/validation.csv')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "   Unnamed: 0      id                                          reference  \\\n0      399158  399158            All he's got is that dingy pride of his   \n1      124527  124527          \"Can't you see, Mars is crazy!\" he cried.   \n2      476327  476327  That's a no. No wonder you're not psyched abou...   \n3      235485  235485                 The ass has stuffed you with money   \n4      478338  478338                   I get wicked bladder infections.   \n\n                                  translation  similarity  lenght_diff  \\\n0     he's got nothing but his fucking pride.    0.709218     0.000000   \n1  \"you can't see, Mym's crazy!\" He screamed.    0.894288     0.023256   \n2   no wonder sex doesn't take you very much.    0.777771     0.207547   \n3                 the donkey does your money.    0.631129     0.200000   \n4          I have a stupid bladder infection.    0.782412     0.057143   \n\n    ref_tox   trn_tox  \n0  0.067650  0.998892  \n1  0.034097  0.762456  \n2  0.021677  0.936896  \n3  0.998838  0.010489  \n4  0.010191  0.997651  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>id</th>\n      <th>reference</th>\n      <th>translation</th>\n      <th>similarity</th>\n      <th>lenght_diff</th>\n      <th>ref_tox</th>\n      <th>trn_tox</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>399158</td>\n      <td>399158</td>\n      <td>All he's got is that dingy pride of his</td>\n      <td>he's got nothing but his fucking pride.</td>\n      <td>0.709218</td>\n      <td>0.000000</td>\n      <td>0.067650</td>\n      <td>0.998892</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>124527</td>\n      <td>124527</td>\n      <td>\"Can't you see, Mars is crazy!\" he cried.</td>\n      <td>\"you can't see, Mym's crazy!\" He screamed.</td>\n      <td>0.894288</td>\n      <td>0.023256</td>\n      <td>0.034097</td>\n      <td>0.762456</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>476327</td>\n      <td>476327</td>\n      <td>That's a no. No wonder you're not psyched abou...</td>\n      <td>no wonder sex doesn't take you very much.</td>\n      <td>0.777771</td>\n      <td>0.207547</td>\n      <td>0.021677</td>\n      <td>0.936896</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>235485</td>\n      <td>235485</td>\n      <td>The ass has stuffed you with money</td>\n      <td>the donkey does your money.</td>\n      <td>0.631129</td>\n      <td>0.200000</td>\n      <td>0.998838</td>\n      <td>0.010489</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>478338</td>\n      <td>478338</td>\n      <td>I get wicked bladder infections.</td>\n      <td>I have a stupid bladder infection.</td>\n      <td>0.782412</td>\n      <td>0.057143</td>\n      <td>0.010191</td>\n      <td>0.997651</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def encode(smple, vcblry):\n",
    "    return [vcblry.freqs[str(i)] for i in smple]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "\n",
    "class Text2TextDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataframe: pd.DataFrame, vocab = None, max_size=100):\n",
    "        self.dataframe = dataframe\n",
    "        self._preprocess()\n",
    "        self.vocab = vocab or self._create_vocab()\n",
    "\n",
    "    def _preprocess(self):\n",
    "        self.dataframe['reference'] = self.dataframe['reference'].str.lower()\n",
    "        self.dataframe['translation'] = self.dataframe['translation'].str.lower()\n",
    "\n",
    "        # self.references = [['<SOS>']+sentence.split()+['<EOS>'] for sentence in self.dataframe['reference']]\n",
    "        # self.translations =  [['<SOS>']+sentence.split()+['<EOS>'] for sentence in self.dataframe['translation']]\n",
    "        self.references = [sentence.split() for sentence in self.dataframe['reference']]\n",
    "        self.translations =  [sentence.split() for sentence in self.dataframe['translation']]\n",
    "\n",
    "    def _yield_tokens(self, sentences):\n",
    "        for sample in sentences:\n",
    "            yield sample\n",
    "\n",
    "    def _create_vocab(self):\n",
    "        # creates vocabulary that is used for encoding\n",
    "        # the sequence of tokens (splitted sentence)\n",
    "        vocab = build_vocab_from_iterator(self._yield_tokens(self.references + self.translations))\n",
    "        return vocab\n",
    "\n",
    "    def _get_reference(self, index: int) -> list:\n",
    "        # retrieves sentence from dataset by index\n",
    "        sent = self.references[index]\n",
    "        if self.vocab is None:\n",
    "            return sent\n",
    "        return encode(sent, self.vocab)\n",
    "\n",
    "    def _get_translation(self, index: int) -> list:\n",
    "        # retrieves tags from dataset by index\n",
    "        sent = self.translations[index]\n",
    "        if self.vocab is None:\n",
    "            return sent\n",
    "        return encode(sent, self.vocab)\n",
    "\n",
    "    def __getitem__(self, index) -> tuple[list, list]:\n",
    "        return self._get_reference(index), self._get_translation(index)\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.references)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "693332lines [00:01, 645654.33lines/s]\n"
     ]
    }
   ],
   "source": [
    "train_dataset = Text2TextDataset(dataframe=train_df)\n",
    "val_dataset = Text2TextDataset(dataframe=val_df, vocab=train_dataset.vocab)\n",
    "test_dataset = Text2TextDataset(dataframe=test_df, vocab=train_dataset.vocab)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "['all', \"he's\", 'got', 'is', 'that', 'dingy', 'pride', 'of', 'his']"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.references[0]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "253"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_size = 50\n",
    "\n",
    "for sent in train_dataset.references + val_dataset.references + test_dataset.references:\n",
    "    max_size = max(max_size, len(sent))\n",
    "\n",
    "max_size"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "\n",
    "device = 'cpu' # 'cpu' # local machine is on M1 Pro chip\n",
    "\n",
    "def collate_batch(batch: list):\n",
    "    references_batch, translation_batch = [], []\n",
    "    for _reference, _translation in batch:\n",
    "        _reference_tensor = torch.Tensor(_reference)\n",
    "        _translation_tensor = torch.Tensor(_translation)\n",
    "\n",
    "        sent_padding = torch.Tensor([1] * (max_size - len(_reference)))\n",
    "        ref_padding = torch.Tensor([1] * (max_size - len(_translation_tensor)))\n",
    "\n",
    "        references_batch.append(torch.concat((_reference_tensor, sent_padding)))\n",
    "        translation_batch.append(torch.concat((_translation_tensor, ref_padding)))\n",
    "\n",
    "    return torch.stack(references_batch, dim=0).int().to(device), torch.stack(translation_batch, dim=0).long().to(device)\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_batch)\n",
    "val_dataloader = torch.utils.data.DataLoader(dataset=val_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_batch)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 253])\n",
      "torch.Size([16, 253])\n"
     ]
    }
   ],
   "source": [
    "# just to check that all shapes are correct\n",
    "\n",
    "for batch in train_dataloader:\n",
    "    inp, out = batch\n",
    "    print(inp.shape)\n",
    "    print(out.shape)\n",
    "    break"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "SOS_token = 0\n",
    "EOS_token = 1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, dropout_p=0.1):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size, padding_idx=1)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, batch_first=True)\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "\n",
    "    def forward(self, input):\n",
    "        embedded = self.dropout(self.embedding(input))\n",
    "        output, hidden = self.gru(embedded)\n",
    "        print(f\"encoder output:{output.shape}\")\n",
    "        return output, hidden"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "class BahdanauAttention(nn.Module):\n",
    "    def __init__(self, hidden_size):\n",
    "        super(BahdanauAttention, self).__init__()\n",
    "        self.Wa = nn.Linear(hidden_size, hidden_size)\n",
    "        self.Ua = nn.Linear(hidden_size, hidden_size)\n",
    "        self.Va = nn.Linear(hidden_size, 1)\n",
    "\n",
    "    def forward(self, query, keys):\n",
    "        scores = self.Va(torch.tanh(self.Wa(query) + self.Ua(keys)))\n",
    "        scores = scores.squeeze(2).unsqueeze(1)\n",
    "\n",
    "        weights = F.softmax(scores, dim=-1)\n",
    "        context = torch.bmm(weights, keys)\n",
    "\n",
    "        return context, weights\n",
    "\n",
    "class AttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, dropout_p=0.1):\n",
    "        super(AttnDecoderRNN, self).__init__()\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.attention = BahdanauAttention(hidden_size)\n",
    "        self.gru = nn.GRU(2 * hidden_size, hidden_size, batch_first=True)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "\n",
    "    def forward(self, encoder_outputs, encoder_hidden, target_tensor=None):\n",
    "        batch_size = encoder_outputs.size(0)\n",
    "        decoder_input = torch.empty(batch_size, 1, dtype=torch.long, device=device).fill_(SOS_token)\n",
    "        decoder_hidden = encoder_hidden\n",
    "        decoder_outputs = []\n",
    "        attentions = []\n",
    "\n",
    "        for i in range(max_size):\n",
    "            decoder_output, decoder_hidden, attn_weights = self.forward_step(\n",
    "                decoder_input, decoder_hidden, encoder_outputs\n",
    "            )\n",
    "            # print(f\"decoder_input shape: {decoder_input.shape}\")\n",
    "            # print(f\"decoder_output shape: {decoder_output.shape}\")\n",
    "            decoder_outputs.append(decoder_output)\n",
    "            attentions.append(attn_weights)\n",
    "\n",
    "            if target_tensor is not None:\n",
    "                # Teacher forcing: Feed the target as the next input\n",
    "                # print(f\"target_tensor shape: {target_tensor.shape}\")\n",
    "                decoder_input = target_tensor[:, i].unsqueeze(1) # Teacher forcing\n",
    "                # print(f\"decoder_input shape: {decoder_input.shape}\")\n",
    "            else:\n",
    "                # Without teacher forcing: use its own predictions as the next input\n",
    "                _, topi = decoder_output.topk(1)\n",
    "                decoder_input = topi.squeeze(-1).detach()  # detach from history as input\n",
    "            # print('i end of loop', i)\n",
    "\n",
    "\n",
    "        decoder_outputs = torch.cat(decoder_outputs, dim=0)\n",
    "        # print(f\"decoder_output shape after loop: {decoder_outputs.shape}\")\n",
    "        decoder_outputs = F.log_softmax(decoder_outputs, dim=-1)\n",
    "        attentions = torch.cat(attentions, dim=1)\n",
    "\n",
    "        return decoder_outputs, decoder_hidden, attentions\n",
    "\n",
    "\n",
    "    def forward_step(self, input, hidden, encoder_outputs):\n",
    "        # print('attn decoder forward_step')\n",
    "        embedded =  self.dropout(self.embedding(input))\n",
    "\n",
    "        query = hidden.permute(1, 0, 2)\n",
    "        # print(f'encoder_outputs: {encoder_outputs.shape}')\n",
    "        context, attn_weights = self.attention(query, encoder_outputs)\n",
    "        input_gru = torch.cat((embedded, context), dim=2)\n",
    "\n",
    "        output, hidden = self.gru(input_gru, hidden)\n",
    "        output = self.out(output)\n",
    "\n",
    "        return output, hidden, attn_weights"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "def train_epoch(dataloader, encoder, decoder, encoder_optimizer,\n",
    "                decoder_optimizer, criterion):\n",
    "\n",
    "    total_loss = 0\n",
    "    for data in dataloader:\n",
    "        input_tensor, target_tensor = data\n",
    "\n",
    "        encoder_optimizer.zero_grad()\n",
    "        decoder_optimizer.zero_grad()\n",
    "\n",
    "        print('encoder_outputs calc')\n",
    "        encoder_outputs, encoder_hidden = encoder(input_tensor)\n",
    "\n",
    "        print('decoder_outputs calc')\n",
    "        decoder_outputs, _, _ = decoder(encoder_outputs, encoder_hidden, target_tensor)\n",
    "        print(f'decoder_outputs: {decoder_outputs.shape}')\n",
    "\n",
    "        print('loss calc')\n",
    "        print(decoder_outputs.view(-1, decoder_outputs.size(-1)).shape)\n",
    "        print(target_tensor.view(-1).shape)\n",
    "        loss = criterion(\n",
    "            decoder_outputs.view(-1, decoder_outputs.size(-1)),\n",
    "            target_tensor.view(-1)\n",
    "        )\n",
    "        loss.backward()\n",
    "\n",
    "        encoder_optimizer.step()\n",
    "        decoder_optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    return total_loss / len(dataloader)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.switch_backend('agg')\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # this locator puts ticks at regular intervals\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)\n",
    "\n",
    "def train(train_dataloader, encoder, decoder, n_epochs, learning_rate=0.001,\n",
    "          print_every=100, plot_every=100):\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "\n",
    "    encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        loss = train_epoch(train_dataloader, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "\n",
    "        if epoch % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print('%s (%d %d%%) %.4f' % (timeSince(start, epoch / n_epochs),\n",
    "                                         epoch, epoch / n_epochs * 100, print_loss_avg))\n",
    "\n",
    "        if epoch % plot_every == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total = 0\n",
    "\n",
    "    showPlot(plot_losses)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder, sentence, input_lang, output_lang):\n",
    "    with torch.no_grad():\n",
    "        input_tensor = encode(sentence, input_lang)\n",
    "\n",
    "        encoder_outputs, encoder_hidden = encoder(input_tensor)\n",
    "        decoder_outputs, decoder_hidden, decoder_attn = decoder(encoder_outputs, encoder_hidden)\n",
    "\n",
    "        _, topi = decoder_outputs.topk(1)\n",
    "        decoded_ids = topi.squeeze()\n",
    "\n",
    "        decoded_words = []\n",
    "        for idx in decoded_ids:\n",
    "            if idx.item() == EOS_token:\n",
    "                decoded_words.append('<EOS>')\n",
    "                break\n",
    "            decoded_words.append(output_lang.index2word[idx.item()])\n",
    "    return decoded_words, decoder_attn"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder_outputs calc\n",
      "encoder output:torch.Size([16, 253, 64])\n",
      "decoder_outputs calc\n",
      "decoder_outputs: torch.Size([4048, 1, 262599])\n",
      "loss calc\n",
      "torch.Size([4048, 262599])\n",
      "torch.Size([4048])\n",
      "encoder_outputs calc\n",
      "encoder output:torch.Size([16, 253, 64])\n",
      "decoder_outputs calc\n",
      "decoder_outputs: torch.Size([4048, 1, 262599])\n",
      "loss calc\n",
      "torch.Size([4048, 262599])\n",
      "torch.Size([4048])\n",
      "encoder_outputs calc\n",
      "encoder output:torch.Size([16, 253, 64])\n",
      "decoder_outputs calc\n",
      "decoder_outputs: torch.Size([4048, 1, 262599])\n",
      "loss calc\n",
      "torch.Size([4048, 262599])\n",
      "torch.Size([4048])\n",
      "encoder_outputs calc\n",
      "encoder output:torch.Size([16, 253, 64])\n",
      "decoder_outputs calc\n",
      "decoder_outputs: torch.Size([4048, 1, 262599])\n",
      "loss calc\n",
      "torch.Size([4048, 262599])\n",
      "torch.Size([4048])\n",
      "encoder_outputs calc\n",
      "encoder output:torch.Size([16, 253, 64])\n",
      "decoder_outputs calc\n",
      "decoder_outputs: torch.Size([4048, 1, 262599])\n",
      "loss calc\n",
      "torch.Size([4048, 262599])\n",
      "torch.Size([4048])\n",
      "encoder_outputs calc\n",
      "encoder output:torch.Size([16, 253, 64])\n",
      "decoder_outputs calc\n",
      "decoder_outputs: torch.Size([4048, 1, 262599])\n",
      "loss calc\n",
      "torch.Size([4048, 262599])\n",
      "torch.Size([4048])\n",
      "encoder_outputs calc\n",
      "encoder output:torch.Size([16, 253, 64])\n",
      "decoder_outputs calc\n",
      "decoder_outputs: torch.Size([4048, 1, 262599])\n",
      "loss calc\n",
      "torch.Size([4048, 262599])\n",
      "torch.Size([4048])\n",
      "encoder_outputs calc\n",
      "encoder output:torch.Size([16, 253, 64])\n",
      "decoder_outputs calc\n",
      "decoder_outputs: torch.Size([4048, 1, 262599])\n",
      "loss calc\n",
      "torch.Size([4048, 262599])\n",
      "torch.Size([4048])\n",
      "encoder_outputs calc\n",
      "encoder output:torch.Size([16, 253, 64])\n",
      "decoder_outputs calc\n",
      "decoder_outputs: torch.Size([4048, 1, 262599])\n",
      "loss calc\n",
      "torch.Size([4048, 262599])\n",
      "torch.Size([4048])\n",
      "encoder_outputs calc\n",
      "encoder output:torch.Size([16, 253, 64])\n",
      "decoder_outputs calc\n",
      "decoder_outputs: torch.Size([4048, 1, 262599])\n",
      "loss calc\n",
      "torch.Size([4048, 262599])\n",
      "torch.Size([4048])\n",
      "encoder_outputs calc\n",
      "encoder output:torch.Size([16, 253, 64])\n",
      "decoder_outputs calc\n",
      "decoder_outputs: torch.Size([4048, 1, 262599])\n",
      "loss calc\n",
      "torch.Size([4048, 262599])\n",
      "torch.Size([4048])\n",
      "encoder_outputs calc\n",
      "encoder output:torch.Size([16, 253, 64])\n",
      "decoder_outputs calc\n",
      "decoder_outputs: torch.Size([4048, 1, 262599])\n",
      "loss calc\n",
      "torch.Size([4048, 262599])\n",
      "torch.Size([4048])\n",
      "encoder_outputs calc\n",
      "encoder output:torch.Size([16, 253, 64])\n",
      "decoder_outputs calc\n",
      "decoder_outputs: torch.Size([4048, 1, 262599])\n",
      "loss calc\n",
      "torch.Size([4048, 262599])\n",
      "torch.Size([4048])\n",
      "encoder_outputs calc\n",
      "encoder output:torch.Size([16, 253, 64])\n",
      "decoder_outputs calc\n",
      "decoder_outputs: torch.Size([4048, 1, 262599])\n",
      "loss calc\n",
      "torch.Size([4048, 262599])\n",
      "torch.Size([4048])\n",
      "encoder_outputs calc\n",
      "encoder output:torch.Size([16, 253, 64])\n",
      "decoder_outputs calc\n",
      "decoder_outputs: torch.Size([4048, 1, 262599])\n",
      "loss calc\n",
      "torch.Size([4048, 262599])\n",
      "torch.Size([4048])\n",
      "encoder_outputs calc\n",
      "encoder output:torch.Size([16, 253, 64])\n",
      "decoder_outputs calc\n",
      "decoder_outputs: torch.Size([4048, 1, 262599])\n",
      "loss calc\n",
      "torch.Size([4048, 262599])\n",
      "torch.Size([4048])\n",
      "encoder_outputs calc\n",
      "encoder output:torch.Size([16, 253, 64])\n",
      "decoder_outputs calc\n",
      "decoder_outputs: torch.Size([4048, 1, 262599])\n",
      "loss calc\n",
      "torch.Size([4048, 262599])\n",
      "torch.Size([4048])\n",
      "encoder_outputs calc\n",
      "encoder output:torch.Size([16, 253, 64])\n",
      "decoder_outputs calc\n",
      "decoder_outputs: torch.Size([4048, 1, 262599])\n",
      "loss calc\n",
      "torch.Size([4048, 262599])\n",
      "torch.Size([4048])\n",
      "encoder_outputs calc\n",
      "encoder output:torch.Size([16, 253, 64])\n",
      "decoder_outputs calc\n",
      "decoder_outputs: torch.Size([4048, 1, 262599])\n",
      "loss calc\n",
      "torch.Size([4048, 262599])\n",
      "torch.Size([4048])\n",
      "encoder_outputs calc\n",
      "encoder output:torch.Size([16, 253, 64])\n",
      "decoder_outputs calc\n",
      "decoder_outputs: torch.Size([4048, 1, 262599])\n",
      "loss calc\n",
      "torch.Size([4048, 262599])\n",
      "torch.Size([4048])\n",
      "encoder_outputs calc\n",
      "encoder output:torch.Size([16, 253, 64])\n",
      "decoder_outputs calc\n",
      "decoder_outputs: torch.Size([4048, 1, 262599])\n",
      "loss calc\n",
      "torch.Size([4048, 262599])\n",
      "torch.Size([4048])\n",
      "encoder_outputs calc\n",
      "encoder output:torch.Size([16, 253, 64])\n",
      "decoder_outputs calc\n",
      "decoder_outputs: torch.Size([4048, 1, 262599])\n",
      "loss calc\n",
      "torch.Size([4048, 262599])\n",
      "torch.Size([4048])\n",
      "encoder_outputs calc\n",
      "encoder output:torch.Size([16, 253, 64])\n",
      "decoder_outputs calc\n",
      "decoder_outputs: torch.Size([4048, 1, 262599])\n",
      "loss calc\n",
      "torch.Size([4048, 262599])\n",
      "torch.Size([4048])\n",
      "encoder_outputs calc\n",
      "encoder output:torch.Size([16, 253, 64])\n",
      "decoder_outputs calc\n",
      "decoder_outputs: torch.Size([4048, 1, 262599])\n",
      "loss calc\n",
      "torch.Size([4048, 262599])\n",
      "torch.Size([4048])\n",
      "encoder_outputs calc\n",
      "encoder output:torch.Size([16, 253, 64])\n",
      "decoder_outputs calc\n",
      "decoder_outputs: torch.Size([4048, 1, 262599])\n",
      "loss calc\n",
      "torch.Size([4048, 262599])\n",
      "torch.Size([4048])\n",
      "encoder_outputs calc\n",
      "encoder output:torch.Size([16, 253, 64])\n",
      "decoder_outputs calc\n",
      "decoder_outputs: torch.Size([4048, 1, 262599])\n",
      "loss calc\n",
      "torch.Size([4048, 262599])\n",
      "torch.Size([4048])\n",
      "encoder_outputs calc\n",
      "encoder output:torch.Size([16, 253, 64])\n",
      "decoder_outputs calc\n",
      "decoder_outputs: torch.Size([4048, 1, 262599])\n",
      "loss calc\n",
      "torch.Size([4048, 262599])\n",
      "torch.Size([4048])\n",
      "encoder_outputs calc\n",
      "encoder output:torch.Size([16, 253, 64])\n",
      "decoder_outputs calc\n",
      "decoder_outputs: torch.Size([4048, 1, 262599])\n",
      "loss calc\n",
      "torch.Size([4048, 262599])\n",
      "torch.Size([4048])\n",
      "encoder_outputs calc\n",
      "encoder output:torch.Size([16, 253, 64])\n",
      "decoder_outputs calc\n",
      "decoder_outputs: torch.Size([4048, 1, 262599])\n",
      "loss calc\n",
      "torch.Size([4048, 262599])\n",
      "torch.Size([4048])\n",
      "encoder_outputs calc\n",
      "encoder output:torch.Size([16, 253, 64])\n",
      "decoder_outputs calc\n",
      "decoder_outputs: torch.Size([4048, 1, 262599])\n",
      "loss calc\n",
      "torch.Size([4048, 262599])\n",
      "torch.Size([4048])\n",
      "encoder_outputs calc\n",
      "encoder output:torch.Size([16, 253, 64])\n",
      "decoder_outputs calc\n",
      "decoder_outputs: torch.Size([4048, 1, 262599])\n",
      "loss calc\n",
      "torch.Size([4048, 262599])\n",
      "torch.Size([4048])\n",
      "encoder_outputs calc\n",
      "encoder output:torch.Size([16, 253, 64])\n",
      "decoder_outputs calc\n",
      "decoder_outputs: torch.Size([4048, 1, 262599])\n",
      "loss calc\n",
      "torch.Size([4048, 262599])\n",
      "torch.Size([4048])\n",
      "encoder_outputs calc\n",
      "encoder output:torch.Size([16, 253, 64])\n",
      "decoder_outputs calc\n",
      "decoder_outputs: torch.Size([4048, 1, 262599])\n",
      "loss calc\n",
      "torch.Size([4048, 262599])\n",
      "torch.Size([4048])\n",
      "encoder_outputs calc\n",
      "encoder output:torch.Size([16, 253, 64])\n",
      "decoder_outputs calc\n",
      "decoder_outputs: torch.Size([4048, 1, 262599])\n",
      "loss calc\n",
      "torch.Size([4048, 262599])\n",
      "torch.Size([4048])\n",
      "encoder_outputs calc\n",
      "encoder output:torch.Size([16, 253, 64])\n",
      "decoder_outputs calc\n",
      "decoder_outputs: torch.Size([4048, 1, 262599])\n",
      "loss calc\n",
      "torch.Size([4048, 262599])\n",
      "torch.Size([4048])\n",
      "encoder_outputs calc\n",
      "encoder output:torch.Size([16, 253, 64])\n",
      "decoder_outputs calc\n",
      "decoder_outputs: torch.Size([4048, 1, 262599])\n",
      "loss calc\n",
      "torch.Size([4048, 262599])\n",
      "torch.Size([4048])\n",
      "encoder_outputs calc\n",
      "encoder output:torch.Size([16, 253, 64])\n",
      "decoder_outputs calc\n",
      "decoder_outputs: torch.Size([4048, 1, 262599])\n",
      "loss calc\n",
      "torch.Size([4048, 262599])\n",
      "torch.Size([4048])\n",
      "encoder_outputs calc\n",
      "encoder output:torch.Size([16, 253, 64])\n",
      "decoder_outputs calc\n",
      "decoder_outputs: torch.Size([4048, 1, 262599])\n",
      "loss calc\n",
      "torch.Size([4048, 262599])\n",
      "torch.Size([4048])\n",
      "encoder_outputs calc\n",
      "encoder output:torch.Size([16, 253, 64])\n",
      "decoder_outputs calc\n",
      "decoder_outputs: torch.Size([4048, 1, 262599])\n",
      "loss calc\n",
      "torch.Size([4048, 262599])\n",
      "torch.Size([4048])\n",
      "encoder_outputs calc\n",
      "encoder output:torch.Size([16, 253, 64])\n",
      "decoder_outputs calc\n",
      "decoder_outputs: torch.Size([4048, 1, 262599])\n",
      "loss calc\n",
      "torch.Size([4048, 262599])\n",
      "torch.Size([4048])\n",
      "encoder_outputs calc\n",
      "encoder output:torch.Size([16, 253, 64])\n",
      "decoder_outputs calc\n",
      "decoder_outputs: torch.Size([4048, 1, 262599])\n",
      "loss calc\n",
      "torch.Size([4048, 262599])\n",
      "torch.Size([4048])\n",
      "encoder_outputs calc\n",
      "encoder output:torch.Size([16, 253, 64])\n",
      "decoder_outputs calc\n",
      "decoder_outputs: torch.Size([4048, 1, 262599])\n",
      "loss calc\n",
      "torch.Size([4048, 262599])\n",
      "torch.Size([4048])\n",
      "encoder_outputs calc\n",
      "encoder output:torch.Size([16, 253, 64])\n",
      "decoder_outputs calc\n",
      "decoder_outputs: torch.Size([4048, 1, 262599])\n",
      "loss calc\n",
      "torch.Size([4048, 262599])\n",
      "torch.Size([4048])\n",
      "encoder_outputs calc\n",
      "encoder output:torch.Size([16, 253, 64])\n",
      "decoder_outputs calc\n",
      "decoder_outputs: torch.Size([4048, 1, 262599])\n",
      "loss calc\n",
      "torch.Size([4048, 262599])\n",
      "torch.Size([4048])\n",
      "encoder_outputs calc\n",
      "encoder output:torch.Size([16, 253, 64])\n",
      "decoder_outputs calc\n",
      "decoder_outputs: torch.Size([4048, 1, 262599])\n",
      "loss calc\n",
      "torch.Size([4048, 262599])\n",
      "torch.Size([4048])\n",
      "encoder_outputs calc\n",
      "encoder output:torch.Size([16, 253, 64])\n",
      "decoder_outputs calc\n",
      "decoder_outputs: torch.Size([4048, 1, 262599])\n",
      "loss calc\n",
      "torch.Size([4048, 262599])\n",
      "torch.Size([4048])\n",
      "encoder_outputs calc\n",
      "encoder output:torch.Size([16, 253, 64])\n",
      "decoder_outputs calc\n",
      "decoder_outputs: torch.Size([4048, 1, 262599])\n",
      "loss calc\n",
      "torch.Size([4048, 262599])\n",
      "torch.Size([4048])\n",
      "encoder_outputs calc\n",
      "encoder output:torch.Size([16, 253, 64])\n",
      "decoder_outputs calc\n",
      "decoder_outputs: torch.Size([4048, 1, 262599])\n",
      "loss calc\n",
      "torch.Size([4048, 262599])\n",
      "torch.Size([4048])\n",
      "encoder_outputs calc\n",
      "encoder output:torch.Size([16, 253, 64])\n",
      "decoder_outputs calc\n",
      "decoder_outputs: torch.Size([4048, 1, 262599])\n",
      "loss calc\n",
      "torch.Size([4048, 262599])\n",
      "torch.Size([4048])\n",
      "encoder_outputs calc\n",
      "encoder output:torch.Size([16, 253, 64])\n",
      "decoder_outputs calc\n",
      "decoder_outputs: torch.Size([4048, 1, 262599])\n",
      "loss calc\n",
      "torch.Size([4048, 262599])\n",
      "torch.Size([4048])\n",
      "encoder_outputs calc\n",
      "encoder output:torch.Size([16, 253, 64])\n",
      "decoder_outputs calc\n",
      "decoder_outputs: torch.Size([4048, 1, 262599])\n",
      "loss calc\n",
      "torch.Size([4048, 262599])\n",
      "torch.Size([4048])\n",
      "encoder_outputs calc\n",
      "encoder output:torch.Size([16, 253, 64])\n",
      "decoder_outputs calc\n",
      "decoder_outputs: torch.Size([4048, 1, 262599])\n",
      "loss calc\n",
      "torch.Size([4048, 262599])\n",
      "torch.Size([4048])\n",
      "encoder_outputs calc\n",
      "encoder output:torch.Size([16, 253, 64])\n",
      "decoder_outputs calc\n",
      "decoder_outputs: torch.Size([4048, 1, 262599])\n",
      "loss calc\n",
      "torch.Size([4048, 262599])\n",
      "torch.Size([4048])\n",
      "encoder_outputs calc\n",
      "encoder output:torch.Size([16, 253, 64])\n",
      "decoder_outputs calc\n",
      "decoder_outputs: torch.Size([4048, 1, 262599])\n",
      "loss calc\n",
      "torch.Size([4048, 262599])\n",
      "torch.Size([4048])\n",
      "encoder_outputs calc\n",
      "encoder output:torch.Size([16, 253, 64])\n",
      "decoder_outputs calc\n",
      "decoder_outputs: torch.Size([4048, 1, 262599])\n",
      "loss calc\n",
      "torch.Size([4048, 262599])\n",
      "torch.Size([4048])\n",
      "encoder_outputs calc\n",
      "encoder output:torch.Size([16, 253, 64])\n",
      "decoder_outputs calc\n",
      "decoder_outputs: torch.Size([4048, 1, 262599])\n",
      "loss calc\n",
      "torch.Size([4048, 262599])\n",
      "torch.Size([4048])\n",
      "encoder_outputs calc\n",
      "encoder output:torch.Size([16, 253, 64])\n",
      "decoder_outputs calc\n",
      "decoder_outputs: torch.Size([4048, 1, 262599])\n",
      "loss calc\n",
      "torch.Size([4048, 262599])\n",
      "torch.Size([4048])\n",
      "encoder_outputs calc\n",
      "encoder output:torch.Size([16, 253, 64])\n",
      "decoder_outputs calc\n",
      "decoder_outputs: torch.Size([4048, 1, 262599])\n",
      "loss calc\n",
      "torch.Size([4048, 262599])\n",
      "torch.Size([4048])\n",
      "encoder_outputs calc\n",
      "encoder output:torch.Size([16, 253, 64])\n",
      "decoder_outputs calc\n",
      "decoder_outputs: torch.Size([4048, 1, 262599])\n",
      "loss calc\n",
      "torch.Size([4048, 262599])\n",
      "torch.Size([4048])\n",
      "encoder_outputs calc\n",
      "encoder output:torch.Size([16, 253, 64])\n",
      "decoder_outputs calc\n",
      "decoder_outputs: torch.Size([4048, 1, 262599])\n",
      "loss calc\n",
      "torch.Size([4048, 262599])\n",
      "torch.Size([4048])\n",
      "encoder_outputs calc\n",
      "encoder output:torch.Size([16, 253, 64])\n",
      "decoder_outputs calc\n",
      "decoder_outputs: torch.Size([4048, 1, 262599])\n",
      "loss calc\n",
      "torch.Size([4048, 262599])\n",
      "torch.Size([4048])\n",
      "encoder_outputs calc\n",
      "encoder output:torch.Size([16, 253, 64])\n",
      "decoder_outputs calc\n",
      "decoder_outputs: torch.Size([4048, 1, 262599])\n",
      "loss calc\n",
      "torch.Size([4048, 262599])\n",
      "torch.Size([4048])\n",
      "encoder_outputs calc\n",
      "encoder output:torch.Size([16, 253, 64])\n",
      "decoder_outputs calc\n",
      "decoder_outputs: torch.Size([4048, 1, 262599])\n",
      "loss calc\n",
      "torch.Size([4048, 262599])\n",
      "torch.Size([4048])\n",
      "encoder_outputs calc\n",
      "encoder output:torch.Size([16, 253, 64])\n",
      "decoder_outputs calc\n",
      "decoder_outputs: torch.Size([4048, 1, 262599])\n",
      "loss calc\n",
      "torch.Size([4048, 262599])\n",
      "torch.Size([4048])\n",
      "encoder_outputs calc\n",
      "encoder output:torch.Size([16, 253, 64])\n",
      "decoder_outputs calc\n",
      "decoder_outputs: torch.Size([4048, 1, 262599])\n",
      "loss calc\n",
      "torch.Size([4048, 262599])\n",
      "torch.Size([4048])\n",
      "encoder_outputs calc\n",
      "encoder output:torch.Size([16, 253, 64])\n",
      "decoder_outputs calc\n",
      "decoder_outputs: torch.Size([4048, 1, 262599])\n",
      "loss calc\n",
      "torch.Size([4048, 262599])\n",
      "torch.Size([4048])\n",
      "encoder_outputs calc\n",
      "encoder output:torch.Size([16, 253, 64])\n",
      "decoder_outputs calc\n",
      "decoder_outputs: torch.Size([4048, 1, 262599])\n",
      "loss calc\n",
      "torch.Size([4048, 262599])\n",
      "torch.Size([4048])\n",
      "encoder_outputs calc\n",
      "encoder output:torch.Size([16, 253, 64])\n",
      "decoder_outputs calc\n",
      "decoder_outputs: torch.Size([4048, 1, 262599])\n",
      "loss calc\n",
      "torch.Size([4048, 262599])\n",
      "torch.Size([4048])\n",
      "encoder_outputs calc\n",
      "encoder output:torch.Size([16, 253, 64])\n",
      "decoder_outputs calc\n",
      "decoder_outputs: torch.Size([4048, 1, 262599])\n",
      "loss calc\n",
      "torch.Size([4048, 262599])\n",
      "torch.Size([4048])\n",
      "encoder_outputs calc\n",
      "encoder output:torch.Size([16, 253, 64])\n",
      "decoder_outputs calc\n",
      "decoder_outputs: torch.Size([4048, 1, 262599])\n",
      "loss calc\n",
      "torch.Size([4048, 262599])\n",
      "torch.Size([4048])\n",
      "encoder_outputs calc\n",
      "encoder output:torch.Size([16, 253, 64])\n",
      "decoder_outputs calc\n",
      "decoder_outputs: torch.Size([4048, 1, 262599])\n",
      "loss calc\n",
      "torch.Size([4048, 262599])\n",
      "torch.Size([4048])\n",
      "encoder_outputs calc\n",
      "encoder output:torch.Size([16, 253, 64])\n",
      "decoder_outputs calc\n",
      "decoder_outputs: torch.Size([4048, 1, 262599])\n",
      "loss calc\n",
      "torch.Size([4048, 262599])\n",
      "torch.Size([4048])\n",
      "encoder_outputs calc\n",
      "encoder output:torch.Size([16, 253, 64])\n",
      "decoder_outputs calc\n",
      "decoder_outputs: torch.Size([4048, 1, 262599])\n",
      "loss calc\n",
      "torch.Size([4048, 262599])\n",
      "torch.Size([4048])\n",
      "encoder_outputs calc\n",
      "encoder output:torch.Size([16, 253, 64])\n",
      "decoder_outputs calc\n",
      "decoder_outputs: torch.Size([4048, 1, 262599])\n",
      "loss calc\n",
      "torch.Size([4048, 262599])\n",
      "torch.Size([4048])\n",
      "encoder_outputs calc\n",
      "encoder output:torch.Size([16, 253, 64])\n",
      "decoder_outputs calc\n",
      "decoder_outputs: torch.Size([4048, 1, 262599])\n",
      "loss calc\n",
      "torch.Size([4048, 262599])\n",
      "torch.Size([4048])\n",
      "encoder_outputs calc\n",
      "encoder output:torch.Size([16, 253, 64])\n",
      "decoder_outputs calc\n",
      "decoder_outputs: torch.Size([4048, 1, 262599])\n",
      "loss calc\n",
      "torch.Size([4048, 262599])\n",
      "torch.Size([4048])\n",
      "encoder_outputs calc\n",
      "encoder output:torch.Size([16, 253, 64])\n",
      "decoder_outputs calc\n",
      "decoder_outputs: torch.Size([4048, 1, 262599])\n",
      "loss calc\n",
      "torch.Size([4048, 262599])\n",
      "torch.Size([4048])\n",
      "encoder_outputs calc\n",
      "encoder output:torch.Size([16, 253, 64])\n",
      "decoder_outputs calc\n",
      "decoder_outputs: torch.Size([4048, 1, 262599])\n",
      "loss calc\n",
      "torch.Size([4048, 262599])\n",
      "torch.Size([4048])\n",
      "encoder_outputs calc\n",
      "encoder output:torch.Size([16, 253, 64])\n",
      "decoder_outputs calc\n",
      "decoder_outputs: torch.Size([4048, 1, 262599])\n",
      "loss calc\n",
      "torch.Size([4048, 262599])\n",
      "torch.Size([4048])\n",
      "encoder_outputs calc\n",
      "encoder output:torch.Size([16, 253, 64])\n",
      "decoder_outputs calc\n",
      "decoder_outputs: torch.Size([4048, 1, 262599])\n",
      "loss calc\n",
      "torch.Size([4048, 262599])\n",
      "torch.Size([4048])\n",
      "encoder_outputs calc\n",
      "encoder output:torch.Size([16, 253, 64])\n",
      "decoder_outputs calc\n",
      "decoder_outputs: torch.Size([4048, 1, 262599])\n",
      "loss calc\n",
      "torch.Size([4048, 262599])\n",
      "torch.Size([4048])\n",
      "encoder_outputs calc\n",
      "encoder output:torch.Size([16, 253, 64])\n",
      "decoder_outputs calc\n",
      "decoder_outputs: torch.Size([4048, 1, 262599])\n",
      "loss calc\n",
      "torch.Size([4048, 262599])\n",
      "torch.Size([4048])\n",
      "encoder_outputs calc\n",
      "encoder output:torch.Size([16, 253, 64])\n",
      "decoder_outputs calc\n",
      "decoder_outputs: torch.Size([4048, 1, 262599])\n",
      "loss calc\n",
      "torch.Size([4048, 262599])\n",
      "torch.Size([4048])\n",
      "encoder_outputs calc\n",
      "encoder output:torch.Size([16, 253, 64])\n",
      "decoder_outputs calc\n",
      "decoder_outputs: torch.Size([4048, 1, 262599])\n",
      "loss calc\n",
      "torch.Size([4048, 262599])\n",
      "torch.Size([4048])\n",
      "encoder_outputs calc\n",
      "encoder output:torch.Size([16, 253, 64])\n",
      "decoder_outputs calc\n",
      "decoder_outputs: torch.Size([4048, 1, 262599])\n",
      "loss calc\n",
      "torch.Size([4048, 262599])\n",
      "torch.Size([4048])\n",
      "encoder_outputs calc\n",
      "encoder output:torch.Size([16, 253, 64])\n",
      "decoder_outputs calc\n",
      "decoder_outputs: torch.Size([4048, 1, 262599])\n",
      "loss calc\n",
      "torch.Size([4048, 262599])\n",
      "torch.Size([4048])\n",
      "encoder_outputs calc\n",
      "encoder output:torch.Size([16, 253, 64])\n",
      "decoder_outputs calc\n",
      "decoder_outputs: torch.Size([4048, 1, 262599])\n",
      "loss calc\n",
      "torch.Size([4048, 262599])\n",
      "torch.Size([4048])\n",
      "encoder_outputs calc\n",
      "encoder output:torch.Size([16, 253, 64])\n",
      "decoder_outputs calc\n",
      "decoder_outputs: torch.Size([4048, 1, 262599])\n",
      "loss calc\n",
      "torch.Size([4048, 262599])\n",
      "torch.Size([4048])\n",
      "encoder_outputs calc\n",
      "encoder output:torch.Size([16, 253, 64])\n",
      "decoder_outputs calc\n",
      "decoder_outputs: torch.Size([4048, 1, 262599])\n",
      "loss calc\n",
      "torch.Size([4048, 262599])\n",
      "torch.Size([4048])\n",
      "encoder_outputs calc\n",
      "encoder output:torch.Size([16, 253, 64])\n",
      "decoder_outputs calc\n",
      "decoder_outputs: torch.Size([4048, 1, 262599])\n",
      "loss calc\n",
      "torch.Size([4048, 262599])\n",
      "torch.Size([4048])\n",
      "encoder_outputs calc\n",
      "encoder output:torch.Size([16, 253, 64])\n",
      "decoder_outputs calc\n",
      "decoder_outputs: torch.Size([4048, 1, 262599])\n",
      "loss calc\n",
      "torch.Size([4048, 262599])\n",
      "torch.Size([4048])\n",
      "encoder_outputs calc\n",
      "encoder output:torch.Size([16, 253, 64])\n",
      "decoder_outputs calc\n",
      "decoder_outputs: torch.Size([4048, 1, 262599])\n",
      "loss calc\n",
      "torch.Size([4048, 262599])\n",
      "torch.Size([4048])\n",
      "encoder_outputs calc\n",
      "encoder output:torch.Size([16, 253, 64])\n",
      "decoder_outputs calc\n",
      "decoder_outputs: torch.Size([4048, 1, 262599])\n",
      "loss calc\n",
      "torch.Size([4048, 262599])\n",
      "torch.Size([4048])\n",
      "encoder_outputs calc\n",
      "encoder output:torch.Size([16, 253, 64])\n",
      "decoder_outputs calc\n",
      "decoder_outputs: torch.Size([4048, 1, 262599])\n",
      "loss calc\n",
      "torch.Size([4048, 262599])\n",
      "torch.Size([4048])\n",
      "encoder_outputs calc\n",
      "encoder output:torch.Size([16, 253, 64])\n",
      "decoder_outputs calc\n",
      "decoder_outputs: torch.Size([4048, 1, 262599])\n",
      "loss calc\n",
      "torch.Size([4048, 262599])\n",
      "torch.Size([4048])\n",
      "encoder_outputs calc\n",
      "encoder output:torch.Size([16, 253, 64])\n",
      "decoder_outputs calc\n",
      "decoder_outputs: torch.Size([4048, 1, 262599])\n",
      "loss calc\n",
      "torch.Size([4048, 262599])\n",
      "torch.Size([4048])\n",
      "encoder_outputs calc\n",
      "encoder output:torch.Size([16, 253, 64])\n",
      "decoder_outputs calc\n",
      "decoder_outputs: torch.Size([4048, 1, 262599])\n",
      "loss calc\n",
      "torch.Size([4048, 262599])\n",
      "torch.Size([4048])\n",
      "encoder_outputs calc\n",
      "encoder output:torch.Size([16, 253, 64])\n",
      "decoder_outputs calc\n",
      "decoder_outputs: torch.Size([4048, 1, 262599])\n",
      "loss calc\n",
      "torch.Size([4048, 262599])\n",
      "torch.Size([4048])\n",
      "encoder_outputs calc\n",
      "encoder output:torch.Size([16, 253, 64])\n",
      "decoder_outputs calc\n",
      "decoder_outputs: torch.Size([4048, 1, 262599])\n",
      "loss calc\n",
      "torch.Size([4048, 262599])\n",
      "torch.Size([4048])\n",
      "encoder_outputs calc\n",
      "encoder output:torch.Size([16, 253, 64])\n",
      "decoder_outputs calc\n",
      "decoder_outputs: torch.Size([4048, 1, 262599])\n",
      "loss calc\n",
      "torch.Size([4048, 262599])\n",
      "torch.Size([4048])\n",
      "encoder_outputs calc\n",
      "encoder output:torch.Size([16, 253, 64])\n",
      "decoder_outputs calc\n",
      "decoder_outputs: torch.Size([4048, 1, 262599])\n",
      "loss calc\n",
      "torch.Size([4048, 262599])\n",
      "torch.Size([4048])\n",
      "encoder_outputs calc\n",
      "encoder output:torch.Size([16, 253, 64])\n",
      "decoder_outputs calc\n",
      "decoder_outputs: torch.Size([4048, 1, 262599])\n",
      "loss calc\n",
      "torch.Size([4048, 262599])\n",
      "torch.Size([4048])\n",
      "encoder_outputs calc\n",
      "encoder output:torch.Size([16, 253, 64])\n",
      "decoder_outputs calc\n",
      "decoder_outputs: torch.Size([4048, 1, 262599])\n",
      "loss calc\n",
      "torch.Size([4048, 262599])\n",
      "torch.Size([4048])\n",
      "encoder_outputs calc\n",
      "encoder output:torch.Size([16, 253, 64])\n",
      "decoder_outputs calc\n",
      "decoder_outputs: torch.Size([4048, 1, 262599])\n",
      "loss calc\n",
      "torch.Size([4048, 262599])\n",
      "torch.Size([4048])\n",
      "encoder_outputs calc\n",
      "encoder output:torch.Size([16, 253, 64])\n",
      "decoder_outputs calc\n",
      "decoder_outputs: torch.Size([4048, 1, 262599])\n",
      "loss calc\n",
      "torch.Size([4048, 262599])\n",
      "torch.Size([4048])\n",
      "encoder_outputs calc\n",
      "encoder output:torch.Size([16, 253, 64])\n",
      "decoder_outputs calc\n",
      "decoder_outputs: torch.Size([4048, 1, 262599])\n",
      "loss calc\n",
      "torch.Size([4048, 262599])\n",
      "torch.Size([4048])\n",
      "encoder_outputs calc\n",
      "encoder output:torch.Size([16, 253, 64])\n",
      "decoder_outputs calc\n",
      "decoder_outputs: torch.Size([4048, 1, 262599])\n",
      "loss calc\n",
      "torch.Size([4048, 262599])\n",
      "torch.Size([4048])\n",
      "encoder_outputs calc\n",
      "encoder output:torch.Size([16, 253, 64])\n",
      "decoder_outputs calc\n",
      "decoder_outputs: torch.Size([4048, 1, 262599])\n",
      "loss calc\n",
      "torch.Size([4048, 262599])\n",
      "torch.Size([4048])\n",
      "encoder_outputs calc\n",
      "encoder output:torch.Size([16, 253, 64])\n",
      "decoder_outputs calc\n",
      "decoder_outputs: torch.Size([4048, 1, 262599])\n",
      "loss calc\n",
      "torch.Size([4048, 262599])\n",
      "torch.Size([4048])\n",
      "encoder_outputs calc\n",
      "encoder output:torch.Size([16, 253, 64])\n",
      "decoder_outputs calc\n",
      "decoder_outputs: torch.Size([4048, 1, 262599])\n",
      "loss calc\n",
      "torch.Size([4048, 262599])\n",
      "torch.Size([4048])\n",
      "encoder_outputs calc\n",
      "encoder output:torch.Size([16, 253, 64])\n",
      "decoder_outputs calc\n",
      "decoder_outputs: torch.Size([4048, 1, 262599])\n",
      "loss calc\n",
      "torch.Size([4048, 262599])\n",
      "torch.Size([4048])\n",
      "encoder_outputs calc\n",
      "encoder output:torch.Size([16, 253, 64])\n",
      "decoder_outputs calc\n",
      "decoder_outputs: torch.Size([4048, 1, 262599])\n",
      "loss calc\n",
      "torch.Size([4048, 262599])\n",
      "torch.Size([4048])\n",
      "encoder_outputs calc\n",
      "encoder output:torch.Size([16, 253, 64])\n",
      "decoder_outputs calc\n",
      "decoder_outputs: torch.Size([4048, 1, 262599])\n",
      "loss calc\n",
      "torch.Size([4048, 262599])\n",
      "torch.Size([4048])\n",
      "encoder_outputs calc\n",
      "encoder output:torch.Size([16, 253, 64])\n",
      "decoder_outputs calc\n",
      "decoder_outputs: torch.Size([4048, 1, 262599])\n",
      "loss calc\n",
      "torch.Size([4048, 262599])\n",
      "torch.Size([4048])\n",
      "encoder_outputs calc\n",
      "encoder output:torch.Size([16, 253, 64])\n",
      "decoder_outputs calc\n",
      "decoder_outputs: torch.Size([4048, 1, 262599])\n",
      "loss calc\n",
      "torch.Size([4048, 262599])\n",
      "torch.Size([4048])\n",
      "encoder_outputs calc\n",
      "encoder output:torch.Size([16, 253, 64])\n",
      "decoder_outputs calc\n",
      "decoder_outputs: torch.Size([4048, 1, 262599])\n",
      "loss calc\n",
      "torch.Size([4048, 262599])\n",
      "torch.Size([4048])\n",
      "encoder_outputs calc\n",
      "encoder output:torch.Size([16, 253, 64])\n",
      "decoder_outputs calc\n",
      "decoder_outputs: torch.Size([4048, 1, 262599])\n",
      "loss calc\n",
      "torch.Size([4048, 262599])\n",
      "torch.Size([4048])\n",
      "encoder_outputs calc\n",
      "encoder output:torch.Size([16, 253, 64])\n",
      "decoder_outputs calc\n",
      "decoder_outputs: torch.Size([4048, 1, 262599])\n",
      "loss calc\n",
      "torch.Size([4048, 262599])\n",
      "torch.Size([4048])\n",
      "encoder_outputs calc\n",
      "encoder output:torch.Size([16, 253, 64])\n",
      "decoder_outputs calc\n",
      "decoder_outputs: torch.Size([4048, 1, 262599])\n",
      "loss calc\n",
      "torch.Size([4048, 262599])\n",
      "torch.Size([4048])\n",
      "encoder_outputs calc\n",
      "encoder output:torch.Size([16, 253, 64])\n",
      "decoder_outputs calc\n",
      "decoder_outputs: torch.Size([4048, 1, 262599])\n",
      "loss calc\n",
      "torch.Size([4048, 262599])\n",
      "torch.Size([4048])\n",
      "encoder_outputs calc\n",
      "encoder output:torch.Size([16, 253, 64])\n",
      "decoder_outputs calc\n",
      "decoder_outputs: torch.Size([4048, 1, 262599])\n",
      "loss calc\n",
      "torch.Size([4048, 262599])\n",
      "torch.Size([4048])\n",
      "encoder_outputs calc\n",
      "encoder output:torch.Size([16, 253, 64])\n",
      "decoder_outputs calc\n",
      "decoder_outputs: torch.Size([4048, 1, 262599])\n",
      "loss calc\n",
      "torch.Size([4048, 262599])\n",
      "torch.Size([4048])\n",
      "encoder_outputs calc\n",
      "encoder output:torch.Size([16, 253, 64])\n",
      "decoder_outputs calc\n",
      "decoder_outputs: torch.Size([4048, 1, 262599])\n",
      "loss calc\n",
      "torch.Size([4048, 262599])\n",
      "torch.Size([4048])\n",
      "encoder_outputs calc\n",
      "encoder output:torch.Size([16, 253, 64])\n",
      "decoder_outputs calc\n",
      "decoder_outputs: torch.Size([4048, 1, 262599])\n",
      "loss calc\n",
      "torch.Size([4048, 262599])\n",
      "torch.Size([4048])\n",
      "encoder_outputs calc\n",
      "encoder output:torch.Size([16, 253, 64])\n",
      "decoder_outputs calc\n",
      "decoder_outputs: torch.Size([4048, 1, 262599])\n",
      "loss calc\n",
      "torch.Size([4048, 262599])\n",
      "torch.Size([4048])\n",
      "encoder_outputs calc\n",
      "encoder output:torch.Size([16, 253, 64])\n",
      "decoder_outputs calc\n",
      "decoder_outputs: torch.Size([4048, 1, 262599])\n",
      "loss calc\n",
      "torch.Size([4048, 262599])\n",
      "torch.Size([4048])\n",
      "encoder_outputs calc\n",
      "encoder output:torch.Size([16, 253, 64])\n",
      "decoder_outputs calc\n",
      "decoder_outputs: torch.Size([4048, 1, 262599])\n",
      "loss calc\n",
      "torch.Size([4048, 262599])\n",
      "torch.Size([4048])\n",
      "encoder_outputs calc\n",
      "encoder output:torch.Size([16, 253, 64])\n",
      "decoder_outputs calc\n",
      "decoder_outputs: torch.Size([4048, 1, 262599])\n",
      "loss calc\n",
      "torch.Size([4048, 262599])\n",
      "torch.Size([4048])\n",
      "encoder_outputs calc\n",
      "encoder output:torch.Size([16, 253, 64])\n",
      "decoder_outputs calc\n",
      "decoder_outputs: torch.Size([4048, 1, 262599])\n",
      "loss calc\n",
      "torch.Size([4048, 262599])\n",
      "torch.Size([4048])\n",
      "encoder_outputs calc\n",
      "encoder output:torch.Size([16, 253, 64])\n",
      "decoder_outputs calc\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[18], line 7\u001B[0m\n\u001B[1;32m      4\u001B[0m encoder \u001B[38;5;241m=\u001B[39m EncoderRNN(vocab_size, hidden_size)\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[1;32m      5\u001B[0m decoder \u001B[38;5;241m=\u001B[39m AttnDecoderRNN(hidden_size, vocab_size)\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[0;32m----> 7\u001B[0m \u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain_dataloader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mencoder\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdecoder\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m10\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mprint_every\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m5\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mplot_every\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m5\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[16], line 25\u001B[0m, in \u001B[0;36mtrain\u001B[0;34m(train_dataloader, encoder, decoder, n_epochs, learning_rate, print_every, plot_every)\u001B[0m\n\u001B[1;32m     22\u001B[0m criterion \u001B[38;5;241m=\u001B[39m nn\u001B[38;5;241m.\u001B[39mCrossEntropyLoss()\n\u001B[1;32m     24\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m epoch \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m1\u001B[39m, n_epochs \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m):\n\u001B[0;32m---> 25\u001B[0m     loss \u001B[38;5;241m=\u001B[39m \u001B[43mtrain_epoch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain_dataloader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mencoder\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdecoder\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mencoder_optimizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdecoder_optimizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcriterion\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     26\u001B[0m     print_loss_total \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m loss\n\u001B[1;32m     27\u001B[0m     plot_loss_total \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m loss\n",
      "Cell \u001B[0;32mIn[14], line 16\u001B[0m, in \u001B[0;36mtrain_epoch\u001B[0;34m(dataloader, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion)\u001B[0m\n\u001B[1;32m     14\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdecoder_outputs calc\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m     15\u001B[0m decoder_outputs, _, _ \u001B[38;5;241m=\u001B[39m decoder(encoder_outputs, encoder_hidden, target_tensor)\n\u001B[0;32m---> 16\u001B[0m \u001B[38;5;28;43mprint\u001B[39;49m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdecoder_outputs: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mdecoder_outputs\u001B[38;5;241m.\u001B[39mshape\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m     18\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mloss calc\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m     19\u001B[0m \u001B[38;5;28mprint\u001B[39m(decoder_outputs\u001B[38;5;241m.\u001B[39mview(\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m, decoder_outputs\u001B[38;5;241m.\u001B[39msize(\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m))\u001B[38;5;241m.\u001B[39mshape)\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "hidden_size = 64\n",
    "vocab_size = 262598 + 1 #len(train_dataset.vocab)\n",
    "\n",
    "encoder = EncoderRNN(vocab_size, hidden_size).to(device)\n",
    "decoder = AttnDecoderRNN(hidden_size, vocab_size).to(device)\n",
    "\n",
    "train(train_dataloader, encoder, decoder, 10, print_every=5, plot_every=5)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### It took more than 90 minutes, and even one epoch has not executed, so I stopped the training. It is not a good solution (at least for my setup)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
