{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Hypothesis 1 test\n",
    "Create my own model and train it on given dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import torch\n",
    "\n",
    "torch.manual_seed(420)\n",
    "np.random.seed(420)\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('../data/internal/train.csv')\n",
    "test_df = pd.read_csv('../data/internal/test.csv')\n",
    "val_df = pd.read_csv('../data/internal/validation.csv')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "   Unnamed: 0      id                                          reference  \\\n0      399158  399158            All he's got is that dingy pride of his   \n1      124527  124527          \"Can't you see, Mars is crazy!\" he cried.   \n2      476327  476327  That's a no. No wonder you're not psyched abou...   \n3      235485  235485                 The ass has stuffed you with money   \n4      478338  478338                   I get wicked bladder infections.   \n\n                                  translation  similarity  lenght_diff  \\\n0     he's got nothing but his fucking pride.    0.709218     0.000000   \n1  \"you can't see, Mym's crazy!\" He screamed.    0.894288     0.023256   \n2   no wonder sex doesn't take you very much.    0.777771     0.207547   \n3                 the donkey does your money.    0.631129     0.200000   \n4          I have a stupid bladder infection.    0.782412     0.057143   \n\n    ref_tox   trn_tox  \n0  0.067650  0.998892  \n1  0.034097  0.762456  \n2  0.021677  0.936896  \n3  0.998838  0.010489  \n4  0.010191  0.997651  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>id</th>\n      <th>reference</th>\n      <th>translation</th>\n      <th>similarity</th>\n      <th>lenght_diff</th>\n      <th>ref_tox</th>\n      <th>trn_tox</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>399158</td>\n      <td>399158</td>\n      <td>All he's got is that dingy pride of his</td>\n      <td>he's got nothing but his fucking pride.</td>\n      <td>0.709218</td>\n      <td>0.000000</td>\n      <td>0.067650</td>\n      <td>0.998892</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>124527</td>\n      <td>124527</td>\n      <td>\"Can't you see, Mars is crazy!\" he cried.</td>\n      <td>\"you can't see, Mym's crazy!\" He screamed.</td>\n      <td>0.894288</td>\n      <td>0.023256</td>\n      <td>0.034097</td>\n      <td>0.762456</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>476327</td>\n      <td>476327</td>\n      <td>That's a no. No wonder you're not psyched abou...</td>\n      <td>no wonder sex doesn't take you very much.</td>\n      <td>0.777771</td>\n      <td>0.207547</td>\n      <td>0.021677</td>\n      <td>0.936896</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>235485</td>\n      <td>235485</td>\n      <td>The ass has stuffed you with money</td>\n      <td>the donkey does your money.</td>\n      <td>0.631129</td>\n      <td>0.200000</td>\n      <td>0.998838</td>\n      <td>0.010489</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>478338</td>\n      <td>478338</td>\n      <td>I get wicked bladder infections.</td>\n      <td>I have a stupid bladder infection.</td>\n      <td>0.782412</td>\n      <td>0.057143</td>\n      <td>0.010191</td>\n      <td>0.997651</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "def encode(smple, vcblry):\n",
    "    return [vcblry.freqs[str(i)] for i in smple]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "\n",
    "class Text2TextDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataframe: pd.DataFrame, vocab = None, max_size=100):\n",
    "        self.dataframe = dataframe\n",
    "        self._preprocess()\n",
    "        self.vocab = vocab or self._create_vocab()\n",
    "\n",
    "    def _preprocess(self):\n",
    "        self.dataframe['reference'] = self.dataframe['reference'].str.lower()\n",
    "        self.dataframe['translation'] = self.dataframe['translation'].str.lower()\n",
    "\n",
    "        self.references = [sentence.split() for sentence in self.dataframe['reference']]\n",
    "        self.translations = [sentence.split() for sentence in self.dataframe['translation']]\n",
    "\n",
    "    def _yield_tokens(self, sentences):\n",
    "        for sample in sentences:\n",
    "            yield sample\n",
    "\n",
    "    def _create_vocab(self):\n",
    "        # creates vocabulary that is used for encoding\n",
    "        # the sequence of tokens (splitted sentence)\n",
    "        vocab = build_vocab_from_iterator(self._yield_tokens(self.references + self.translations))\n",
    "        return vocab\n",
    "\n",
    "    def _get_reference(self, index: int) -> list:\n",
    "        # retrieves sentence from dataset by index\n",
    "        sent = self.references[index]\n",
    "        if self.vocab is None:\n",
    "            return sent\n",
    "        return encode(sent, self.vocab)\n",
    "\n",
    "    def _get_translation(self, index: int) -> list:\n",
    "        # retrieves tags from dataset by index\n",
    "        sent = self.translations[index]\n",
    "        if self.vocab is None:\n",
    "            return sent\n",
    "        return encode(sent, self.vocab)\n",
    "\n",
    "    def __getitem__(self, index) -> tuple[list, list]:\n",
    "        return self._get_reference(index), self._get_translation(index)\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.references)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "693332lines [00:01, 670715.46lines/s]\n"
     ]
    }
   ],
   "source": [
    "train_dataset = Text2TextDataset(dataframe=train_df)\n",
    "val_dataset = Text2TextDataset(dataframe=val_df, vocab=train_dataset.vocab)\n",
    "test_dataset = Text2TextDataset(dataframe=test_df, vocab=train_dataset.vocab)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "data": {
      "text/plain": "['all', \"he's\", 'got', 'is', 'that', 'dingy', 'pride', 'of', 'his']"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.references[0]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "data": {
      "text/plain": "253"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_size = 50\n",
    "\n",
    "for sent in train_dataset.references + val_dataset.references + test_dataset.references:\n",
    "    max_size = max(max_size, len(sent))\n",
    "\n",
    "max_size"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "\n",
    "device = 'mps' if torch.cuda.is_available() else 'cpu' # local machine is on M1 Pro chip\n",
    "\n",
    "def collate_batch(batch: list):\n",
    "    references_batch, translation_batch = [], []\n",
    "    for _reference, _translation in batch:\n",
    "        _reference_tensor = torch.Tensor(_reference)\n",
    "        _translation_tensor = torch.Tensor(_translation)\n",
    "\n",
    "        sent_padding = torch.Tensor([1] * (max_size - len(_reference)))\n",
    "        ref_padding = torch.Tensor([0] * (max_size - len(_translation_tensor)))\n",
    "\n",
    "        references_batch.append(torch.concat((_reference_tensor, sent_padding)))\n",
    "        translation_batch.append(torch.concat((_translation_tensor, ref_padding)))\n",
    "\n",
    "    return torch.stack(references_batch, dim=0).int().T.to(device), torch.stack(translation_batch, dim=0).T.long().to(device)\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_batch)\n",
    "val_dataloader = torch.utils.data.DataLoader(dataset=val_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_batch)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([253, 128])\n",
      "torch.Size([253, 128])\n"
     ]
    }
   ],
   "source": [
    "# just to check that all shapes are correct\n",
    "\n",
    "for batch in train_dataloader:\n",
    "    inp, out = batch\n",
    "    print(inp.shape)\n",
    "    print(out.shape)\n",
    "    break"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
